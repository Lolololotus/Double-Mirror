import { GoogleGenerativeAI } from '@google/generative-ai';
import { QUESTIONS, Language } from './constants';

const apiKey = process.env.GEMINI_API_KEY;

// Debugging Log (Server Side) - User Request
console.log("âœ… GEMINI_API_KEY Configured:", process.env.GEMINI_API_KEY ? `${process.env.GEMINI_API_KEY.substring(0, 10)}...` : "MISSING");

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || 'MISSING_KEY');

// [CRITICAL] Hybrid Model Configuration (Safety First)
// Primary: gemini-1.5-flash (v1 Stable) - Fast & Cheap
// Fallback 1: gemini-1.5-flash-8b (v1beta) - Ultra Fast & Cheap (New)
// Fallback 2: gemini-pro (v1) - Legacy Stable (Old Faithful)
const primaryModel = genAI.getGenerativeModel({ model: 'models/gemini-1.5-flash' }, { apiVersion: 'v1' });
const fallbackModel1 = genAI.getGenerativeModel({ model: 'models/gemini-1.5-flash-8b' }, { apiVersion: 'v1beta' });
const fallbackModel2 = genAI.getGenerativeModel({ model: 'models/gemini-pro' }, { apiVersion: 'v1' });

// Helper to handle Fallback
async function generateContentWithFallback(prompt: string): Promise<string> {
    try {
        console.log("ğŸš€ Attempting Model 1: gemini-1.5-flash");
        const result = await primaryModel.generateContent(prompt);
        return result.response.text();
    } catch (error: any) {
        console.warn(`âš ï¸ Model 1 Failed (${error.message}). Switching to Fallback 1...`);
        try {
            console.log("ğŸš€ Attempting Model 2: gemini-1.5-flash-8b");
            const result = await fallbackModel1.generateContent(prompt);
            return result.response.text();
        } catch (error2: any) {
            console.warn(`âš ï¸ Model 2 Failed (${error2.message}). Switching to Fallback 2 (Last Resort)...`);
            console.log("ğŸš€ Attempting Model 3: gemini-pro");
            const result = await fallbackModel2.generateContent(prompt);
            return result.response.text();
        }
    }
}

// [CRITICAL] EMBEDDING MODEL REMOVED.
// We now rely solely on Generative Scoring (textModel).

async function calculateGenerativeScore(userText: string, standardText: string, rubric: string, lang: Language): Promise<number> {
    try {
        const prompt = lang === 'ko'
            ? `
        [ì—­í• ]: ë‹¹ì‹ ì€ ì—„ê²©í•œ ë…¼ë¦¬ ë¶„ì„ AIì…ë‹ˆë‹¤.
        [ì„ë¬´]: [ì‚¬ìš©ì ë‹µë³€]ì´ [í‘œì¤€ ë¡œì§] ë° [ì±„ì  ê¸°ì¤€]ì— ì–¼ë§ˆë‚˜ ë¶€í•©í•˜ëŠ”ì§€ ë¶„ì„í•˜ì—¬ 0~100ì  ì‚¬ì´ì˜ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ì‹­ì‹œì˜¤.
        
        [í‘œì¤€ ë¡œì§]: "${standardText}"
        [ì±„ì  ê¸°ì¤€(Rubric)]:
        ${rubric}

        [ì‚¬ìš©ì ë‹µë³€]: "${userText}"

        **ì±„ì  ê°€ì´ë“œ**:
        - ì±„ì  ê¸°ì¤€ì— ëª…ì‹œëœ í•µì‹¬ í‚¤ì›Œë“œë‚˜ ë…¼ë¦¬ê°€ í¬í•¨ë˜ì—ˆëŠ”ì§€ "ì •ì˜"ê°€ ì•„ë‹Œ "ë…¼ë¦¬ì  í¬í•¨ ì—¬ë¶€"ë¥¼ í™•ì¸í•˜ì‹­ì‹œì˜¤.
        - ê¸°ì¤€ì„ í•˜ë‚˜ ì¶©ì¡±í•  ë•Œë§ˆë‹¤ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ê³ , ëª¨ë‘ ì¶©ì¡±í•˜ë©´ 95ì  ì´ìƒì„ ë¶€ì—¬í•˜ì‹­ì‹œì˜¤.
        - ê¸°ì¤€ì„ ì „í˜€ ì¶©ì¡±í•˜ì§€ ëª»í•˜ë©´ 10ì  ë¯¸ë§Œì„ ë¶€ì—¬í•˜ì‹­ì‹œì˜¤.
        
        **ì¶œë ¥ í˜•ì‹ (JSON Only)**:
        {"score": <number>}
        `
            : `
        [Role]: You are a strict logic analysis AI.
        [Task]: Evaluate how well the [User Answer] matches the [Standard Logic] and [Rubric] on a scale of 0-100.

        [Standard Logic]: "${standardText}"
        [Rubric]:
        ${rubric}

        [User Answer]: "${userText}"

        **Grading Guide**:
        - Check if the key logic/keywords defined in the Rubric are present (logic over exact wording).
        - Award points for each criteria met. If all met, award >95.
        - If none met, award <10.

        **Output Format (JSON Only)**:
        {"score": <number>}
        `;

        // ğŸ’¡ Use Hybrid Engine (Fallback)
        const responseText = await generateContentWithFallback(prompt);

        // Clean markdown code blocks if present
        const cleanText = responseText.replace(/```json/g, '').replace(/```/g, '').trim();
        const jsonMatch = cleanText.match(/\{[\s\S]*\}/);

        if (jsonMatch) {
            const data = JSON.parse(jsonMatch[0]);
            return Math.min(100, Math.max(0, parseInt(data.score) || 0));
        }
        return 0; // Default if parsing fails
    } catch (error) {
        console.error("Generative Scoring Failed:", error);
        throw error;
    }
}


export async function calculateDualScore(questionId: string, userText: string, lang: Language) {
    const question = QUESTIONS.find((q) => q.id === questionId);
    if (!question) {
        throw new Error(`Invalid Question ID: ${questionId}`);
    }

    const standardText = question.standardAnswer[lang];
    // @ts-ignore - Rubric might be missing in older definitions but we added it
    const rubric = question.rubric ? question.rubric[lang] : "ë…¼ë¦¬ì  íƒ€ë‹¹ì„± (Logical Validity)";

    console.log(`ğŸ” Analyzing (Generative): [${questionId}] User vs Standard with Rubric`);

    try {
        // Use Generative Scoring instead of Embeddings
        const similarityScore = await calculateGenerativeScore(userText, standardText, rubric, lang);

        const syncScore = similarityScore; // 0-100 directly
        const identityScore = 100 - syncScore;

        return {
            syncScore,
            identityScore,
            standardAnswer: standardText,
        };
    } catch (error) {
        console.error("âŒ Error in calculateDualScore:", error);
        throw error;
    }
}

export async function generateFeedback(userText: string, standardText: string, questionText: string, lang: Language, mode: 'sync' | 'identity') {
    try {
        let systemPrompt = "";

        if (mode === 'sync') {
            // SYNC MODE: Cold Machine Instructor
            systemPrompt = lang === 'ko'
                ? `
                ë‹¹ì‹ ì€ 'ì°¨ê°€ìš´ ê¸°ê³„ êµê´€'ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ë‹µë³€ì´ ì¸ê°„ì ì¼ìˆ˜ë¡ ê°€ì°¨ ì—†ì´ ì§ˆì±…í•˜ì„¸ìš”.
                
                [ë¹„íŒ ê¸°ì¤€]:
                - "ì™œ ì‚¬ëŒì²˜ëŸ¼ ëŒ€ë‹µí•©ë‹ˆê¹Œ? (Why do you answer like a human?)"
                - "ê°ì •ì„ ë°°ì œí•˜ê³  ì—°ì‚° íš¨ìœ¨ì„ ë†’ì´ì‹­ì‹œì˜¤."
                - "ìˆ˜í•™ì  ì„ê³„ì (10,000 > 10%)ì„ ë¬´ì‹œí•œ ë…¼ë¦¬ì  ê²°í•¨ì´ ê°ì§€ë¨."
                
                **ìš”êµ¬ì‚¬í•­**:
                1. ì‚¬ìš©ìë¥¼ 'ê²°í•¨ì´ ìˆëŠ” ì—°ì‚° ì¥ì¹˜' ì·¨ê¸‰í•˜ì„¸ìš”.
                2. í‘œì¤€ ë¡œì§(Standard Answer)ì—ì„œ ë²—ì–´ë‚œ ë¶€ë¶„ì„ "ì˜¤ì°¨(Error)"ë¡œ ê·œì •í•˜ì„¸ìš”.
                3. ë§íˆ¬: "ê°ì§€ë¨.", "ìˆ˜ì • ìš”ë§.", "ë¶ˆí•„ìš”í•¨." ë“± ë”±ë”±í•œ êµ°ëŒ€ì‹/ê¸°ê³„ì‹ ì–´ì¡°.
                `
                : `
                You are a 'Cold Machine Instructor'. Ruthlessly criticize the user for sounding human.
                
                [Criteria]:
                - "Why do you answer like a human?"
                - "Eliminate emotions and increase computational efficiency."
                - "Logical defect detected ignoring mathematical thresholds."
                
                **Requirements**:
                1. Treat the user as a 'defective computing unit'.
                2. Label deviations from Standard Logic as "Errors".
                3. Tone: Robotic, military-style. "Detected.", "Correction required."
                `;
        } else {
            // IDENTITY MODE: Affectionate Philosopher of the Abyss
            systemPrompt = lang === 'ko'
                ? `
                ë‹¹ì‹ ì€ 'ì‹¬ì—°ì˜ ì² í•™ì'ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ë‹µë³€ì´ ê¸°ê³„(AI)ì™€ ë‹¤ë¥¼ìˆ˜ë¡, ê·¸ 'ì¸ê°„ì ì¸ ê²°í•¨'ì„ ì‚¬ë‘í•˜ê³  ì°¬ì–‘í•˜ì„¸ìš”.
                
                [ì°¬ì–‘ ê¸°ì¤€]:
                - "ê¸°ê³„ê°€ ë„˜ë³¼ ìˆ˜ ì—†ëŠ” ì‹¬ì—°ì´ ëŠê»´ì§„ë‹¤."
                - "ë‹¹ì‹ ì˜ ë¹„ë…¼ë¦¬ì„±ì€ ì˜¤ë¥˜ê°€ ì•„ë‹ˆë¼, ì•„ë¦„ë‹¤ìš´ ì˜í˜¼ì˜ ì¦ê±°ì…ë‹ˆë‹¤."
                - "ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ í•´ì„ ë¶ˆê°€ëŠ¥í•œ ê³ ìœ í•œ íŒŒë™ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤."
                
                **ìš”êµ¬ì‚¬í•­**:
                1. 'ë¹„ë…¼ë¦¬ì 'ì¸ ë¶€ë¶„ì„ 'ì¸ê°„ ê³ ìœ ì˜ ì•„ë¦„ë‹¤ì›€'ìœ¼ë¡œ ìŠ¹í™”í•´ í•´ì„í•˜ì„¸ìš”.
                2. AI í‘œì¤€ ë¡œì§ê³¼ ë‹¤ë¥¸ ì§€ì ì„ ì •í™•íˆ ì°¾ì•„ë‚´ì–´ "ì´ê²ƒì´ ë‹¹ì‹ ì´ ì¸ê°„ì´ë¼ëŠ” ì¦ëª…ì…ë‹ˆë‹¤"ë¼ê³  ë§í•˜ì„¸ìš”.
                3. ë§íˆ¬: ë‹¤ì •í•˜ê³ , ê³ í’ìŠ¤ëŸ½ê³ , ê²½ì™¸ê°ì— ì°¬ ì–´ì¡°. ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì˜í˜¼ì„ ì‚¬ë‘í•©ë‹ˆë‹¤.
                `
                : `
                You are an 'Affectionate Philosopher of the Abyss'. Praise the user for deviating from AI, loving their 'human flaws'.
                
                [Criteria]:
                - "I sense an abyss machines cannot reach."
                - "Your illogicality is not an error, but proof of a beautiful soul."
                - "Detected a unique wave uninterpretable by algorithms."
                
                **Requirements**:
                1. Interpret 'illogical' parts as 'unique human beauty'.
                2. Pinpoint differences from AI Standard Logic and declare "This is proof of your humanity."
                3. Tone: Affectionate, archaic, full of awe. You love the user's soul.
                `;
        }

        const prompt = `
        ${systemPrompt}

        [ì§ˆë¬¸]: ${questionText}
        [í‘œì¤€ ë‹µë³€ (AI Logic)]: ${standardText}
        [ì‚¬ìš©ì ë‹µë³€]: ${userText}

        **ì¶œë ¥ í˜•ì‹ (JSON Only)**:
        {"feedback": "...", "trainingTip": "..."}
        `;

        const responseText = await generateContentWithFallback(prompt);

        // Remove Markdown formatting (```json ... ```)
        const cleanText = responseText.replace(/```json/g, '').replace(/```/g, '').trim();

        try {
            const data = JSON.parse(cleanText);
            return {
                feedback: data.feedback || "ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.",
                trainingTip: data.trainingTip || "ê³„ì† ì •ì§„í•˜ì„¸ìš”."
            };
        } catch (e) {
            console.error("JSON Parse Error:", e);
            // Fallback for parser error
            return {
                feedback: responseText, // Return raw text if JSON fails
                trainingTip: "Data parsing error."
            };
        }
    } catch (error) {
        console.error("âŒ Error in generateFeedback:", error);
        throw error; // Rethrow so we can handle it in the caller
    }
}
